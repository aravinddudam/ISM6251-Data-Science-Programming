{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f08fd45e-25fe-4890-9fec-7950ea8add29",
   "metadata": {},
   "source": [
    "## Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443113ea",
   "metadata": {},
   "source": [
    "## U04440266\n",
    "## Aravind Dudam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9bdafe",
   "metadata": {},
   "source": [
    "## Importing the preprocessed data for finding the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31aeac5c-a8d5-483b-a467-d21eaf3703be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# set random seed to ensure that results are repeatable\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac1bad1-8a84-4700-8a64-072d3bdd4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"C:/Users/Aravind Dudam/Downloads/X_train.csv\")\n",
    "X_test = pd.read_csv(\"C:/Users/Aravind Dudam/Downloads/X_test.csv\")\n",
    "y_train = pd.read_csv(\"C:/Users/Aravind Dudam/Downloads/y_train.csv\")\n",
    "y_test = pd.read_csv(\"C:/Users/Aravind Dudam/Downloads/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09041c0-25dc-44cb-9f0f-640b98f02c4f",
   "metadata": {},
   "source": [
    "## Logistic Regression with Random Search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa903c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = [\n",
    "    { 'penalty': ['l2'], 'C': [ 0.1, 1, 10]}\n",
    "]\n",
    "\n",
    "Lr = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = Lr, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7879060e-40a9-4f45-9d02-a0f117db2a9f",
   "metadata": {},
   "source": [
    "## Logistic Regression with Grid Search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f621e55-2c69-4092-8203-440dbee8e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = [\n",
    "    { 'penalty': ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10, 100]}\n",
    "]\n",
    "\n",
    "Lr_grid = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = Lr_grid, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f242c3-ee1f-440d-9ca6-9f2427b7c480",
   "metadata": {},
   "source": [
    "### SVM classification model using Random Search for Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff212b1-3d4f-4fba-87e6-63902aac6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.0001, 0.001, 0.1, 1, 10, 100, 1000], \n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "rand_linear_SVC = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = rand_linear_SVC, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797acc4-04db-4234-aaf7-5b694f7ac2fb",
   "metadata": {},
   "source": [
    "### SVM classification model using Grid Search for Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2ee3b-6ea9-40ca-9287-64a2a2be576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.0001, 0.001, 0.1, 1, 10, 100, 1000], \n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "Grid_Linear_SVC = SVC()\n",
    "grid_search = GridSearchCV(estimator = Grid_Linear_SVC, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e22d704-b443-4fe9-bb2a-c7de16e45d49",
   "metadata": {},
   "source": [
    "### SVM classification model using Random Search for Poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f4c25-6d20-417b-8f8f-28d0cbd60b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001],\n",
    "    'kernel': ['poly']\n",
    "}\n",
    "\n",
    "Random_Poly_SVC = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = Random_Poly_SVC, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610dac6-730f-4918-a85c-e7b3a5cb39ee",
   "metadata": {},
   "source": [
    "### SVM classification model using Grid Search for Poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968bffb8-9bab-470a-8472-32df9b83b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001],\n",
    "    'kernel': ['poly']\n",
    "}\n",
    "\n",
    "\n",
    "Grid_Poly_SVC = SVC()\n",
    "grid_search = GridSearchCV(estimator = Grid_Poly_SVC, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7047c2-5ee2-4bb2-81f4-53927b3c6318",
   "metadata": {},
   "source": [
    "### SVM classification model using Random Search for RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a14d1-01c1-4a6a-a9cc-5fc7a0a01b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.1,1, 10], \n",
    "    'gamma': [1,0.1,0.011],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "Random_rbf_SVC = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = Random_rbf_SVC, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc28099-a15f-41ae-a3dd-bc0b9340f58a",
   "metadata": {},
   "source": [
    "### SVM classification model using Grid Search for rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1069c-2dae-4893-be38-5a48c413c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08463c0a-da11-441b-bad5-4363f1cdbd50",
   "metadata": {},
   "source": [
    "## Random search for decision tree based on the parameters set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2f9ad-dc89-4133-9870-7661569cc6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60cda4-30f0-4578-9a23-e0c9a5c7e13c",
   "metadata": {},
   "source": [
    "## Grid search based on the parameters set for the Grid search for the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ddd05-ec20-4fd1-829b-e5f2429a5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(10,15),  \n",
    "    'min_samples_leaf': np.arange(3,7),\n",
    "    'min_impurity_decrease': np.arange(0.0089, 0.0095, 0.0001),\n",
    "    'max_leaf_nodes': np.arange(8,13), \n",
    "    'max_depth': np.arange(30,35), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree_grid = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree_grid, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f1ddf-cc47-44c1-a671-91a719ff1810",
   "metadata": {},
   "source": [
    "## Inference for the above modeling techniques\n",
    "\n",
    "1. F1 score for Random Search on Logistic Regression is 0.91\n",
    "2. F1 score for grid search on the logistic regression is 0.92\n",
    "3. F1 score for Random Search on Linear SVM is 0.92\n",
    "4. F1 score for Grid Search on Linear SVM is 0.91\n",
    "5. F1 score for Random Search on Poly SVM is 0.91\n",
    "6. F1 score for Grid Search on Poly SVM is 0.91\n",
    "7. F1 score for Random Search on RBF SVM is 0.91\n",
    "8. F1 score for Grid Search on RBF SVM is 0.92\n",
    "9. F1 score for Random Search on Decision tree classifier is 0.93\n",
    "10. F1 score for exhaustive Grid Search on Decision tree classifier is 0.93\n",
    "\n",
    "Based on the provided data, it is evident that the F1 Score metric, when used with optimal parameters obtained through both random and grid search methods, identifies the Decision Tree as the model with the highest F1 score of 0.93. Therefore, we can conclude that the Decision Tree model outperforms the others in terms of F1 value.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
