{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f08fd45e-25fe-4890-9fec-7950ea8add29",
   "metadata": {},
   "source": [
    "# WE07 Neural Network Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443113ea",
   "metadata": {},
   "source": [
    "### Predicting the service type of electric connection given to different customers by states and electric stations  by building ML models such as Logistic regression, Support vector Machine(SVM), and Decision tree. Hyperparameter tuning can be used to improve the accuracy of the models. To evaluate the performance of the models, metrics F1 score is being used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9bdafe",
   "metadata": {},
   "source": [
    "## Importing the preprocessed data for finding the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31aeac5c-a8d5-483b-a467-d21eaf3703be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# set random seed to ensure that results are repeatable\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac1bad1-8a84-4700-8a64-072d3bdd4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"C:/Users/Aravind Dudam/Downloads/DSP/X_train.csv\")\n",
    "X_test = pd.read_csv(\"C:/Users/Aravind Dudam/Downloads/DSP/X_test.csv\")\n",
    "y_train = pd.read_csv(\"C:/Users/Aravind Dudam/Downloads/DSP/y_train.csv\")\n",
    "y_test = pd.read_csv(\"C:/Users/Aravind Dudam/Downloads/DSP/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c70fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09041c0-25dc-44cb-9f0f-640b98f02c4f",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression with Random Search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b280b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1 score is 0.9928636256262976\n",
      "... with parameters: {'C': 9.50714306409916}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "    'C': uniform(loc=0, scale=10)\n",
    "}\n",
    "\n",
    "Lr = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator=Lr, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                                 scoring=score_measure, n_jobs=-1, random_state=42)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestLr = rand_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7879060e-40a9-4f45-9d02-a0f117db2a9f",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression with Grid Search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1441e8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.89002732        nan 0.9051593         nan 0.98774153\n",
      "        nan 0.99286363        nan 0.99390193]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1 score is 0.9939019288868232\n",
      "... with parameters: {'C': 100, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "Lr = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator=Lr, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, n_jobs=-1)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestLr = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4c1c7",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab919108",
   "metadata": {},
   "source": [
    "## Random Search for Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae1cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1 score is 0.9969230769230769\n",
      "... with parameters: {'C': 51.41096648805749, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "     'C': reciprocal(0.001, 1000), \n",
    "     'kernel': ['linear']\n",
    "}\n",
    "\n",
    "rand_linear_SVC = SVC(max_iter=200)\n",
    "rand_search = RandomizedSearchCV(estimator=rand_linear_SVC, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                                 scoring=score_measure, n_jobs=-1, random_state=42)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestSVC = rand_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797acc4-04db-4234-aaf7-5b694f7ac2fb",
   "metadata": {},
   "source": [
    "## Grid Search for Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b2ee3b-6ea9-40ca-9287-64a2a2be576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1 score is 0.9948654056707064\n",
      "... with parameters: {'C': 10, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "     'kernel': ['linear']\n",
    "}\n",
    "\n",
    "Grid_Linear_SVC = SVC(max_iter=200)\n",
    "grid_search = GridSearchCV(estimator=Grid_Linear_SVC, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, n_jobs=-1)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestSVC = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e22d704-b443-4fe9-bb2a-c7de16e45d49",
   "metadata": {},
   "source": [
    "## Random Search for Polynomial Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b93f4c25-6d20-417b-8f8f-28d0cbd60b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 168 is smaller than n_iter=500. Running 168 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1 score is 0.9959037089312318\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 100.0, 'degree': 3, 'C': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3, 3, 7),\n",
    "    'kernel': ['poly'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 2, 6))\n",
    "}\n",
    "\n",
    "rand_poly_SVC = SVC(max_iter=50)\n",
    "rand_search = RandomizedSearchCV(estimator=rand_poly_SVC, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                                 scoring=score_measure, n_jobs=-1)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestSVC = rand_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610dac6-730f-4918-a85c-e7b3a5cb39ee",
   "metadata": {},
   "source": [
    "## Grid Search for Polynomial Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "968bffb8-9bab-470a-8472-32df9b83b8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1 score is 0.9959037089312318\n",
      "... with parameters: {'C': 0.001, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3, 3, 7),\n",
    "    'kernel': ['poly'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 2, 6))\n",
    "}\n",
    "\n",
    "Grid_poly_SVC = SVC(max_iter=50)\n",
    "grid_search = GridSearchCV(estimator=Grid_poly_SVC, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, n_jobs=-1)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestSVC = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7047c2-5ee2-4bb2-81f4-53927b3c6318",
   "metadata": {},
   "source": [
    "## Random Search for Radial basis function kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947a14d1-01c1-4a6a-a9cc-5fc7a0a01b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 28 is smaller than n_iter=500. Running 28 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "The best f1 score is 0.9969788519637461\n",
      "... with parameters: {'kernel': 'rbf', 'gamma': 0.0001, 'C': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "     'C': np.logspace(-3, 3, 7), \n",
    "     'gamma': [0.0001, 0.001, 0.1, 1], \n",
    "     'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "rand_rbf_SVC = SVC(max_iter=50)\n",
    "rand_search = RandomizedSearchCV(estimator = rand_rbf_SVC, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_model = rand_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc28099-a15f-41ae-a3dd-bc0b9340f58a",
   "metadata": {},
   "source": [
    "## Grid Search for Radial basis function kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a1069c-2dae-4893-be38-5a48c413c99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "The best f1 score is 0.9969788519637461\n",
      "... with parameters: {'C': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "     'C': np.logspace(-3, 3, 7),\n",
    "     'gamma': [0.0001, 0.001, 0.1, 1], \n",
    "     'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "grid_rbf_SVC = SVC(max_iter=50)\n",
    "grid_search = GridSearchCV(estimator = grid_rbf_SVC, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181fe89e",
   "metadata": {},
   "source": [
    "# Decision Tree model using Random Search and Grid Search for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08463c0a-da11-441b-bad5-4363f1cdbd50",
   "metadata": {},
   "source": [
    "## Decision Tree with Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9263a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best f1 score is 1.0\n",
      "... with parameters: {'min_samples_split': 1, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0006000000000000001, 'max_leaf_nodes': 18, 'max_depth': 8, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1, 20),  \n",
    "    'min_samples_leaf': np.arange(1,20),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 20), \n",
    "    'max_depth': np.arange(1,10), \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator=dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                                 scoring=score_measure, verbose=1, n_jobs=-1, # n_jobs=-1 will utilize all available CPUs \n",
    "                                 return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60cda4-30f0-4578-9a23-e0c9a5c7e13c",
   "metadata": {},
   "source": [
    "## Decision Tree with Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc22a48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 320 candidates, totalling 1600 fits\n",
      "The best f1 score is 0.9897921608280347\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 15, 'max_leaf_nodes': 10, 'min_impurity_decrease': 0.0005, 'min_samples_leaf': 10, 'min_samples_split': 30}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(26,36),  \n",
    "    'min_samples_leaf': np.arange(8,16),\n",
    "    'min_impurity_decrease': np.arange( 0.0005, 0.0010, 0.0020),\n",
    "    'max_leaf_nodes': [10,30], \n",
    "    'max_depth': [5,15], \n",
    "    'criterion': ['entropy']\n",
    "}\n",
    "\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267236de",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5ec1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1963386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1096: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 55 s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200) #max_iter - how often we are changing the w's(weight)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cea0930d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3360018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       184\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1072\n",
      "   macro avg       1.00      1.00      1.00      1072\n",
      "weighted avg       1.00      1.00      1.00      1072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7de7297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1096: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1 score is 1.0\n",
      "... with parameters: {'solver': 'sgd', 'max_iter': 5000, 'learning_rate_init': 0.1, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (70, 50, 40), 'alpha': 0.5, 'activation': 'tanh'}\n",
      "CPU times: total: 5min\n",
      "Wall time: 9min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bbe196a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind Dudam\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1096: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1 score is 0.9974522292993632\n",
      "... with parameters: {'activation': 'relu', 'alpha': 0.5, 'hidden_layer_sizes': (90,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 24 s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c2fb3",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "### Based on the evaluation results, the best model appears to be the Neural Network model, as both Random Search and Grid Search achieved an F1 score of 99.7%. This suggests that the Neural Network model may be the most suitable for this particular classification problem.\n",
    "\n",
    "### It is also worth noting that the Logistic Regression models, both with Random Search and Grid Search, performed very well, achieving F1 scores of 99.2% and 99.3%, respectively. The SVM models with both Linear and Radial Basis Function kernels, with both Random Search and Grid Search, also performed well, achieving F1 scores ranging from 99.4% to 99.6%.\n",
    "\n",
    "### The Polynomial Kernel SVM models, with both Random Search and Grid Search, also performed well, achieving F1 scores of 99.5%. However, the Decision Tree models, with both Random Search and Grid Search, had relatively lower F1 scores ranging from 98.5% to 98.7%.\n",
    "\n",
    "### Overall, based on the evaluation results, the Neural Network model using either Random Search or Grid Search is likely the best model for this classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a7f0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
