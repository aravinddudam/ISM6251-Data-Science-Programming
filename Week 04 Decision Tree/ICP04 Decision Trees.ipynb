{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22dbfdb7-3e8c-47cd-86b7-4e76b1a8a850",
   "metadata": {},
   "source": [
    "# ICP04 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c68137",
   "metadata": {},
   "source": [
    "## Aravind Dudam\n",
    "\n",
    "## U04440266"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3147b052",
   "metadata": {},
   "source": [
    "## Library ImportÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a335a277-3190-47fb-87a6-4d5cc76a414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d609b6c-59a2-40cc-bc65-73234545c415",
   "metadata": {},
   "source": [
    "##  Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c995f0-2ca3-4753-b8f3-41281e80fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('E:/DSP/Week 04/airbnb_train_X_price_gte_150.csv')\n",
    "y_train = pd.read_csv('E:/DSP/Week 04/airbnb_train_y_price_gte_150.csv')\n",
    "X_test = pd.read_csv('E:/DSP/Week 04/airbnb_test_X_price_gte_150.csv')\n",
    "y_test = pd.read_csv('E:/DSP/Week 04/airbnb_test_y_price_gte_150.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22d11cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>...</th>\n",
       "      <th>property_type_Condominium</th>\n",
       "      <th>property_type_Dorm</th>\n",
       "      <th>property_type_Entire Floor</th>\n",
       "      <th>property_type_Guesthouse</th>\n",
       "      <th>property_type_House</th>\n",
       "      <th>property_type_Loft</th>\n",
       "      <th>property_type_Other</th>\n",
       "      <th>property_type_Townhouse</th>\n",
       "      <th>property_type_Villa</th>\n",
       "      <th>property_type_unkown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884939</td>\n",
       "      <td>1.012890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539411</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.375655</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.808025</td>\n",
       "      <td>0.861706</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539411</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>2.325470</td>\n",
       "      <td>1.333267</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215255</td>\n",
       "      <td>-0.095632</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017689</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>0.375655</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.857605</td>\n",
       "      <td>-1.058074</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.574789</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.199298</td>\n",
       "      <td>1.125934</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.574789</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.482015</td>\n",
       "      <td>0.675233</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539411</td>\n",
       "      <td>0.564007</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.023296</td>\n",
       "      <td>0.126650</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.131889</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177577</td>\n",
       "      <td>0.691157</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.574789</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.457699</td>\n",
       "      <td>-1.419131</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.131889</td>\n",
       "      <td>0.564007</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.123707</td>\n",
       "      <td>0.262572</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.574789</td>\n",
       "      <td>0.564007</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2488 rows Ã 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      host_is_superhost  host_identity_verified  latitude  longitude  \\\n",
       "0                     0                       0  0.884939   1.012890   \n",
       "1                     0                       1 -1.808025   0.861706   \n",
       "2                     0                       1  0.215255  -0.095632   \n",
       "3                     0                       0 -1.857605  -1.058074   \n",
       "4                     0                       0 -1.199298   1.125934   \n",
       "...                 ...                     ...       ...        ...   \n",
       "2483                  0                       1 -1.482015   0.675233   \n",
       "2484                  0                       1 -0.023296   0.126650   \n",
       "2485                  0                       1  0.177577   0.691157   \n",
       "2486                  0                       1 -1.457699  -1.419131   \n",
       "2487                  0                       1 -0.123707   0.262572   \n",
       "\n",
       "      room_type  accommodates  bathrooms  bedrooms      beds  bed_type  ...  \\\n",
       "0             0      0.539411  -0.441906  0.999675  0.375655         4  ...   \n",
       "1             0      0.539411  -0.441906  2.325470  1.333267         4  ...   \n",
       "2             0     -0.017689  -0.441906 -0.326120  0.375655         4  ...   \n",
       "3             1     -0.574789  -0.441906 -0.326120 -0.581957         4  ...   \n",
       "4             0     -0.574789  -0.441906 -0.326120 -0.581957         4  ...   \n",
       "...         ...           ...        ...       ...       ...       ...  ...   \n",
       "2483          1      0.539411   0.564007 -0.326120 -0.581957         4  ...   \n",
       "2484          1     -1.131889  -0.441906 -0.326120 -0.581957         4  ...   \n",
       "2485          0     -0.574789  -0.441906 -0.326120 -0.581957         4  ...   \n",
       "2486          1     -1.131889   0.564007 -0.326120 -0.581957         4  ...   \n",
       "2487          1     -0.574789   0.564007 -0.326120 -0.581957         4  ...   \n",
       "\n",
       "      property_type_Condominium  property_type_Dorm  \\\n",
       "0                             0                   0   \n",
       "1                             1                   0   \n",
       "2                             0                   0   \n",
       "3                             1                   0   \n",
       "4                             0                   0   \n",
       "...                         ...                 ...   \n",
       "2483                          0                   0   \n",
       "2484                          0                   0   \n",
       "2485                          1                   0   \n",
       "2486                          0                   0   \n",
       "2487                          1                   0   \n",
       "\n",
       "      property_type_Entire Floor  property_type_Guesthouse  \\\n",
       "0                              0                         0   \n",
       "1                              0                         0   \n",
       "2                              0                         0   \n",
       "3                              0                         0   \n",
       "4                              0                         0   \n",
       "...                          ...                       ...   \n",
       "2483                           0                         0   \n",
       "2484                           0                         0   \n",
       "2485                           0                         0   \n",
       "2486                           0                         0   \n",
       "2487                           0                         0   \n",
       "\n",
       "      property_type_House  property_type_Loft  property_type_Other  \\\n",
       "0                       0                   0                    0   \n",
       "1                       0                   0                    0   \n",
       "2                       0                   0                    0   \n",
       "3                       0                   0                    0   \n",
       "4                       1                   0                    0   \n",
       "...                   ...                 ...                  ...   \n",
       "2483                    1                   0                    0   \n",
       "2484                    0                   0                    0   \n",
       "2485                    0                   0                    0   \n",
       "2486                    1                   0                    0   \n",
       "2487                    0                   0                    0   \n",
       "\n",
       "      property_type_Townhouse  property_type_Villa  property_type_unkown  \n",
       "0                           0                    0                     0  \n",
       "1                           0                    0                     0  \n",
       "2                           0                    0                     0  \n",
       "3                           0                    0                     0  \n",
       "4                           0                    0                     0  \n",
       "...                       ...                  ...                   ...  \n",
       "2483                        0                    0                     0  \n",
       "2484                        0                    0                     0  \n",
       "2485                        0                    0                     0  \n",
       "2486                        0                    0                     0  \n",
       "2487                        0                    0                     0  \n",
       "\n",
       "[2488 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9095d03-fb3b-414c-bfbd-bad431b2e3c4",
   "metadata": {},
   "source": [
    "## SVM Classification by using Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "925497c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aravi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=500. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aravi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best precision score is 0.9370404920282969\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 0.01, 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001],\n",
    "    'kernel': ['poly']\n",
    "}\n",
    "\n",
    "RS_Out = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = RS_Out, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cbb835",
   "metadata": {},
   "source": [
    "## SVM Classification by using Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d3bf14-8763-4eaa-b24d-a7e58e0c35df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aravi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best precision score is 0.9370404920282969\n",
      "... with parameters: {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.1,1, 10, 100], \n",
    "     'gamma': [1,0.1,0.01,0.001],\n",
    "    'kernel': ['poly']\n",
    "}\n",
    "\n",
    "GS_out = SVC()\n",
    "grid_search = GridSearchCV(estimator = GS_out, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46585a4c-5471-400f-93bf-2cddaac5cd5d",
   "metadata": {},
   "source": [
    "## Decision tree by using Random search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d7e0e4d-782a-41f6-8be3-8d339d8f7abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best precision score is 0.8553701168468061\n",
      "... with parameters: {'min_samples_split': 30, 'min_samples_leaf': 23, 'min_impurity_decrease': 0.0021, 'max_leaf_nodes': 91, 'max_depth': 35, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aravi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aravi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aravi\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\aravi\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\aravi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.77844887 0.77844887 0.83927765 0.82841043 0.82532953        nan\n",
      " 0.83942426 0.82488631 0.82768187 0.83491274 0.82488631 0.83766907\n",
      " 0.82487201        nan 0.82488631 0.82488631 0.82488631 0.84205182\n",
      " 0.82488631 0.82488631 0.82488631 0.82488631 0.83032083 0.82756901\n",
      " 0.82488631 0.83231997 0.83494371 0.82488631 0.82552271 0.82488631\n",
      " 0.82532953 0.82488631 0.77844887 0.82488631 0.82488631 0.82488631\n",
      " 0.8280068  0.82488631 0.84685032 0.82488631 0.82488631 0.82488631\n",
      " 0.82488631 0.82488631 0.82488631 0.82488631 0.83766907 0.83773101\n",
      " 0.82488631 0.83762658 0.82599224 0.82488631 0.82488631 0.82756901\n",
      " 0.82488631 0.82488631 0.83320275 0.82488631 0.83032083 0.83954218\n",
      " 0.82488631 0.82532953 0.82488631 0.82488631 0.83766907 0.82868301\n",
      " 0.82488631 0.82488631 0.8365337  0.82841043 0.82488631 0.82488631\n",
      " 0.82488631 0.84143592 0.82488631 0.82488631 0.82488631 0.82488631\n",
      " 0.8342016  0.82488631 0.82488631 0.83222366 0.82756901 0.82756901\n",
      " 0.8312966  0.82532953 0.85375491 0.82488631 0.82488631 0.8280068\n",
      " 0.82488631 0.83845651 0.82488631 0.82756901 0.84123466 0.82756901\n",
      " 0.82488631 0.82488631 0.82595586 0.83364647 0.82488631 0.82488631\n",
      " 0.82532953 0.83032083 0.82488631 0.82488631 0.82488631 0.82857656\n",
      " 0.82488631 0.82488631 0.82548825 0.82488631 0.84255416 0.82488631\n",
      " 0.82488631 0.82488631 0.82488631 0.82488631 0.82488631 0.82627955\n",
      " 0.82488631 0.83247073 0.82756901 0.84062648 0.83032083 0.85421748\n",
      " 0.82552271 0.82488631 0.82488631        nan 0.82595586 0.82488631\n",
      " 0.82595586 0.83480762 0.83160136 0.82532057 0.82488631 0.82841043\n",
      " 0.82488631 0.82532953 0.82926049 0.830101   0.8352192  0.84926223\n",
      " 0.82488631 0.82488631 0.83267695 0.82488631 0.85052915 0.82488631\n",
      " 0.82488631 0.82488631 0.82488631 0.83870358 0.82532953 0.83766907\n",
      " 0.8389098  0.82488631        nan 0.82488631 0.82488631 0.82488631\n",
      " 0.82586846 0.82488631 0.82488631 0.82488631 0.8312966  0.83212638\n",
      " 0.77844887 0.82595586 0.82532953 0.82488631 0.82039937 0.82488631\n",
      " 0.82575817 0.82488631 0.82488631 0.84473993 0.82756901 0.83222366\n",
      " 0.83222366 0.82488631 0.82904928 0.82488631 0.82488631 0.82488631\n",
      " 0.82488631 0.82532953 0.83766907 0.82648669 0.83019972 0.82488631\n",
      " 0.84673915 0.83361517 0.82532953 0.82586846 0.77844887 0.82532953\n",
      " 0.82514459 0.82488631 0.82552271 0.82488631 0.8340626  0.82488631\n",
      " 0.82487201 0.82488631 0.82488631 0.83247073 0.83390783 0.84123466\n",
      " 0.82488631 0.82532953 0.82488631 0.82488631 0.82968843 0.82488631\n",
      " 0.83225259 0.8312966  0.82488631 0.84624033 0.82488631 0.82488631\n",
      " 0.84110495 0.8312966  0.83132262 0.83711882 0.83766907 0.82488631\n",
      " 0.82488631 0.82488631 0.82488631 0.82507291 0.82488631 0.82488631\n",
      " 0.77844887 0.82488631 0.82488631 0.84499722 0.82586846 0.82488631\n",
      " 0.82532953 0.83585906 0.83304336 0.82488631 0.82532953 0.82488631\n",
      " 0.82488631 0.83773101 0.82595586 0.82756901 0.82488631 0.82488631\n",
      " 0.82487201 0.77844887 0.82488631 0.84381077 0.83460008 0.82488631\n",
      " 0.84686788 0.8324782  0.82488631 0.82488631 0.82756901 0.82488631\n",
      " 0.83766907 0.82488631 0.82488631 0.84422075 0.82488631 0.83900309\n",
      " 0.82488631 0.82488631 0.82488631 0.82488631 0.83148343 0.82488631\n",
      " 0.82488631 0.82488631 0.84189061 0.83367319 0.84516036 0.82488631\n",
      " 0.82488631 0.8278815  0.82482894 0.83766907 0.82488631 0.82595586\n",
      " 0.84156968 0.82488631 0.84414979 0.82488631 0.82488631 0.82488631\n",
      "        nan 0.83019972 0.83247073 0.83585906 0.82488631 0.84123466\n",
      " 0.77844887 0.82488631 0.82488631 0.82488631 0.82488631 0.82488631\n",
      " 0.8407057  0.82488631 0.82488631 0.77844887 0.82768187 0.84054652\n",
      " 0.82488631 0.82488631 0.82488631 0.83675493 0.82488631 0.82488631\n",
      " 0.82488631 0.83585906 0.82488631 0.82586846 0.84056766 0.83581309\n",
      " 0.83585906 0.82532953 0.82488631 0.82488631 0.82488631 0.8340141\n",
      " 0.83825509 0.83924658 0.82488631 0.82532953 0.83766907 0.82514459\n",
      " 0.82488631 0.82532953 0.82488631 0.84173701 0.82488631 0.82825672\n",
      " 0.82488631 0.82940688 0.82488631 0.8346148  0.82488631 0.83019972\n",
      " 0.82488631 0.77844887 0.82488631 0.83253161 0.83071623 0.83590266\n",
      " 0.82488631 0.82756901 0.82488631 0.82488631 0.82488631 0.83556602\n",
      " 0.84688479 0.82488631 0.82488631 0.83024761 0.82488631 0.82488631\n",
      " 0.82488631 0.83247073 0.83304336 0.77844887 0.82488631 0.82488631\n",
      " 0.82488631 0.82488631 0.82488631 0.8268126  0.83865213 0.82490463\n",
      " 0.77844887 0.84213849 0.82532953 0.84826248 0.82756901 0.82488631\n",
      " 0.82552271 0.8446265  0.83054091 0.82488631 0.82488631 0.82769013\n",
      " 0.82488631 0.83711882 0.82488631 0.82552271 0.82488631 0.82514459\n",
      " 0.82855513 0.82532953 0.82532953 0.82488631 0.82488631 0.82532953\n",
      " 0.83186859 0.77844887 0.82756901 0.82488631 0.85537012 0.82488631\n",
      " 0.82488631 0.82488631 0.83216431 0.82488631 0.82488631 0.82488631\n",
      " 0.82488631 0.82488631 0.84708677 0.82595586 0.82855513 0.82552271\n",
      " 0.82488631 0.82488631 0.83895825 0.84428996 0.82488631 0.82488631\n",
      " 0.83766907 0.77844887 0.82488631 0.82615474 0.82595586 0.82488631\n",
      " 0.83585906 0.83026191 0.83026191 0.82488631 0.83773101 0.82488631\n",
      " 0.83948565 0.83273566 0.82756901 0.83585906 0.82488631 0.82488631\n",
      " 0.8365337  0.82488631 0.83924658 0.82488631 0.83766907 0.82507291\n",
      " 0.82438454 0.83987605 0.82488631 0.84727065 0.77844887 0.83963035\n",
      " 0.82488631 0.83766907 0.82488631 0.84709762 0.82488631 0.83766907\n",
      " 0.82532953 0.82488631 0.82488631 0.84193488 0.82488631 0.8406849\n",
      " 0.82855513 0.83736319 0.84720734 0.82488631 0.82488631 0.82488631\n",
      " 0.82488631 0.82488631 0.84392919 0.77844887 0.82488631 0.82756901\n",
      " 0.82488631 0.82488631 0.82488631 0.83766907 0.82490463 0.82532953\n",
      " 0.82514459 0.82488631 0.82488631 0.82507291 0.83390551 0.8465842\n",
      " 0.82971325 0.82627955 0.82743759 0.83019972 0.82488631 0.83267695\n",
      " 0.82488631 0.83153266]\n",
      "  warnings.warn(\n",
      "C:\\Users\\aravi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.77774902 0.77774902 0.85631015 0.83235552 0.82598391        nan\n",
      " 0.85623245 0.82583601 0.83955617 0.84409992 0.82583601 0.84452029\n",
      " 0.82814917        nan 0.82583601 0.82583601 0.82583601 0.85725471\n",
      " 0.82583601 0.82583601 0.82583601 0.82583601 0.83544251 0.83093316\n",
      " 0.82583601 0.83948086 0.84140665 0.82583601 0.82637164 0.82583601\n",
      " 0.82598391 0.82583601 0.77774902 0.82583601 0.82583601 0.82583601\n",
      " 0.83272552 0.82583601 0.86547833 0.82583601 0.82583601 0.82583601\n",
      " 0.82583601 0.82583601 0.82583601 0.82583601 0.84452029 0.84818137\n",
      " 0.82583601 0.84496355 0.83077589 0.82583601 0.82583601 0.83093316\n",
      " 0.82583601 0.82583601 0.84210027 0.82583601 0.83547245 0.84715573\n",
      " 0.82583601 0.826048   0.82583601 0.82583601 0.84452029 0.83272567\n",
      " 0.82583601 0.82583601 0.83996952 0.83235552 0.82583601 0.82583601\n",
      " 0.82583601 0.85178595 0.82583601 0.82583601 0.82583601 0.82583601\n",
      " 0.84710545 0.82583601 0.82583601 0.83905609 0.83093316 0.83093316\n",
      " 0.83504222 0.826048   0.87695751 0.82583601 0.82583601 0.83272552\n",
      " 0.82583601 0.84714625 0.82583601 0.83093316 0.85036837 0.83093316\n",
      " 0.82583601 0.82583601 0.82697856 0.83978321 0.82583601 0.82583601\n",
      " 0.826048   0.83544251 0.82583601 0.82583601 0.82583601 0.84022157\n",
      " 0.82583601 0.82583601 0.85716141 0.82583601 0.84910088 0.82583601\n",
      " 0.82583601 0.82583601 0.82583601 0.82583601 0.82583601 0.83082791\n",
      " 0.82583601 0.83861476 0.83093316 0.84469235 0.83547245 0.87214664\n",
      " 0.82637164 0.82583601 0.82583601        nan 0.82697856 0.82583601\n",
      " 0.82697856 0.84214072 0.83763724 0.84178608 0.82583601 0.83235552\n",
      " 0.82583601 0.826048   0.83397202 0.83542494 0.84244045 0.8678224\n",
      " 0.82583601 0.82583601 0.84031158 0.82583601 0.8679687  0.82583601\n",
      " 0.82583601 0.82583601 0.82583601 0.84675144 0.826048   0.84449037\n",
      " 0.84840174 0.82583601        nan 0.82583601 0.82583601 0.82583601\n",
      " 0.83087084 0.82583601 0.82583601 0.82583601 0.83504222 0.84917181\n",
      " 0.77774902 0.82697856 0.826048   0.82583601 0.83620896 0.82583601\n",
      " 0.83018155 0.82583601 0.82583601 0.86155488 0.83093316 0.83905609\n",
      " 0.83905609 0.82583601 0.83272057 0.82583601 0.82583601 0.82583601\n",
      " 0.82583601 0.826048   0.84452029 0.83261694 0.83578976 0.82583601\n",
      " 0.85701515 0.84394939 0.82601598 0.83080794 0.77774902 0.826048\n",
      " 0.82851932 0.82583601 0.82637164 0.82583601 0.84009391 0.82583601\n",
      " 0.82814917 0.82583601 0.82583601 0.83861476 0.84170003 0.85036837\n",
      " 0.82583601 0.826048   0.82583601 0.82583601 0.85571537 0.82583601\n",
      " 0.83899004 0.83504222 0.82583601 0.85948421 0.82583601 0.82583601\n",
      " 0.86008377 0.83504222 0.84761411 0.84613639 0.84452029 0.82583601\n",
      " 0.82583601 0.82583601 0.82583601 0.83803457 0.82583601 0.82583601\n",
      " 0.77774902 0.82583601 0.82583601 0.85231332 0.83087084 0.82583601\n",
      " 0.82598391 0.84341642 0.84049152 0.82583601 0.82598391 0.82583601\n",
      " 0.82583601 0.84800719 0.82697856 0.83093316 0.82583601 0.82583601\n",
      " 0.82814917 0.77774902 0.82583601 0.85694604 0.84821528 0.82583601\n",
      " 0.86138449 0.84436034 0.82583601 0.82583601 0.83093316 0.82583601\n",
      " 0.84452029 0.82583601 0.82583601 0.85141261 0.82583601 0.86212147\n",
      " 0.82583601 0.82583601 0.82583601 0.82583601 0.83617732 0.82583601\n",
      " 0.82583601 0.82583601 0.84751659 0.84029205 0.85477917 0.82583601\n",
      " 0.82583601 0.83301112 0.83641593 0.84452029 0.82583601 0.82697856\n",
      " 0.84903845 0.82583601 0.85565316 0.82583601 0.82583601 0.82583601\n",
      "        nan 0.83578976 0.83861476 0.84341642 0.82583601 0.85036837\n",
      " 0.77774902 0.82583601 0.82583601 0.82583601 0.82583601 0.82583601\n",
      " 0.85197904 0.82583601 0.82583601 0.77774902 0.83955617 0.85004907\n",
      " 0.82583601 0.82583601 0.82583601 0.86082265 0.82583601 0.82583601\n",
      " 0.82583601 0.84341642 0.82583601 0.83024509 0.86081172 0.84238417\n",
      " 0.84341642 0.82601598 0.82583601 0.82583601 0.82583601 0.85727965\n",
      " 0.84786933 0.86253741 0.82583601 0.82598391 0.84452029 0.82851932\n",
      " 0.82583601 0.826048   0.82583601 0.84544502 0.82583601 0.8347618\n",
      " 0.82583601 0.8345461  0.82583601 0.87282837 0.82583601 0.83578976\n",
      " 0.82583601 0.77774902 0.82583601 0.84044549 0.92098036 0.86590135\n",
      " 0.82583601 0.83093316 0.82583601 0.82583601 0.82583601 0.8428255\n",
      " 0.86102433 0.82583601 0.82583601 0.83506881 0.82583601 0.82583601\n",
      " 0.82583601 0.83861476 0.84049152 0.77774902 0.82583601 0.82583601\n",
      " 0.82583601 0.82583601 0.82583601 0.83246699 0.86268011 0.8268113\n",
      " 0.77774902 0.85958334 0.82601598 0.86202723 0.83093316 0.82583601\n",
      " 0.82637164 0.85328039 0.86632212 0.82583601 0.82583601 0.83061584\n",
      " 0.82583601 0.84613639 0.82583601 0.82637164 0.82583601 0.82851932\n",
      " 0.83219021 0.826048   0.826048   0.82583601 0.82583601 0.826048\n",
      " 0.86071225 0.77774902 0.83093316 0.82583601 0.86875616 0.82583601\n",
      " 0.82583601 0.82583601 0.84422896 0.82583601 0.82583601 0.82583601\n",
      " 0.82583601 0.82583601 0.85513746 0.82697856 0.83202072 0.82637164\n",
      " 0.82583601 0.82583601 0.86278963 0.84936169 0.82583601 0.82583601\n",
      " 0.84452029 0.77774902 0.82583601 0.83070565 0.82697856 0.82583601\n",
      " 0.84341642 0.83261379 0.83261379 0.82583601 0.84800719 0.82583601\n",
      " 0.85025725 0.85000191 0.83093316 0.84341642 0.82583601 0.82583601\n",
      " 0.83996952 0.82583601 0.86253741 0.82583601 0.84452029 0.83803457\n",
      " 0.88884006 0.84373893 0.82583601 0.86209664 0.77774902 0.84992506\n",
      " 0.82583601 0.84452029 0.82583601 0.86080214 0.82583601 0.84452029\n",
      " 0.826048   0.82583601 0.82583601 0.86488154 0.82583601 0.84862506\n",
      " 0.83202072 0.84882868 0.86477095 0.82583601 0.82583601 0.82583601\n",
      " 0.82583601 0.82583601 0.86359489 0.77774902 0.82583601 0.83093316\n",
      " 0.82583601 0.82583601 0.82583601 0.84452029 0.8268113  0.826048\n",
      " 0.82848866 0.82583601 0.82583601 0.83803457 0.87611791 0.86729866\n",
      " 0.83512085 0.83082791 0.84486453 0.83578976 0.82583601 0.84031158\n",
      " 0.82583601 0.83690262]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586da763",
   "metadata": {},
   "source": [
    "## Decision tree by using Grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "594477da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9072 candidates, totalling 45360 fits\n",
      "The best precision score is 0.8470330066484271\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 15, 'max_leaf_nodes': 162, 'min_impurity_decrease': 0.0048, 'min_samples_leaf': 10, 'min_samples_split': 30}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(30,36),  \n",
    "    'min_samples_leaf': np.arange(6,12),\n",
    "    'min_impurity_decrease': np.arange(0.0048, 0.0054, 0.0001),\n",
    "    'max_leaf_nodes': np.arange(162,168), \n",
    "    'max_depth': np.arange(15,21), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "Dout_GS = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = Dout_GS, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7938994-19ad-46cf-8d2a-220822a797a9",
   "metadata": {},
   "source": [
    "# Discussion:\n",
    "From the data above that the most effective approaches for the Support Vector Machine classifier are random search and grid search is 93%. After accounting for the decision tree results, the optimum grid search CV precision score is 85.3%,Â Â Random search cv, which is 85.5%, is the approach that decision trees perform best when using. In terms of highest precision score, the svm model performs better than decision trees overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043e9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
